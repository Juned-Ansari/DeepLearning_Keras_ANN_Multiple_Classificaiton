{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p7hv79aFsoXl"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "Vj1-yeLwsoe3",
    "outputId": "b17ae425-168b-448f-9967-2b76b5c34532"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3               4\n",
       "0    5.1  3.5  1.4  0.2     Iris-setosa\n",
       "1    4.9  3.0  1.4  0.2     Iris-setosa\n",
       "2    4.7  3.2  1.3  0.2     Iris-setosa\n",
       "3    4.6  3.1  1.5  0.2     Iris-setosa\n",
       "4    5.0  3.6  1.4  0.2     Iris-setosa\n",
       "..   ...  ...  ...  ...             ...\n",
       "145  6.7  3.0  5.2  2.3  Iris-virginica\n",
       "146  6.3  2.5  5.0  1.9  Iris-virginica\n",
       "147  6.5  3.0  5.2  2.0  Iris-virginica\n",
       "148  6.2  3.4  5.4  2.3  Iris-virginica\n",
       "149  5.9  3.0  5.1  1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"iris.data\",header=None)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "moC7ISYDsoku"
   },
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,0:4].values\n",
    "y = dataset.iloc[:,4].values\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder =  LabelEncoder()\n",
    "y1 = encoder.fit_transform(y)\n",
    "Y = pd.get_dummies(y1).values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,Y,test_size=0.1,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "yq9RfsdUwR5U",
    "outputId": "8ac35a75-4b6e-4e24-deba-628d56155738"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "KtRIeS9rwSKJ",
    "outputId": "9eb3a96b-4b32-4dd1-bf24-18c740be91f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "id": "KZ8X63HVswnh",
    "outputId": "fe05700f-99cd-4231-ba24-0261fa6a5bc7"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(4,input_shape=(4,), activation='relu'))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "6QDB8sznsw1h",
    "outputId": "ca4de29f-c8a7-4a76-9c73-3b4be114e3ec"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"Adam\", loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Rs1GTTaTsxCQ",
    "outputId": "17727603-8120-4350-f8ea-e02e22855429"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "135/135 [==============================] - 1s 5ms/step - loss: 2.6545 - accuracy: 0.3481\n",
      "Epoch 2/150\n",
      "135/135 [==============================] - 0s 272us/step - loss: 2.3836 - accuracy: 0.3481\n",
      "Epoch 3/150\n",
      "135/135 [==============================] - 0s 294us/step - loss: 2.1473 - accuracy: 0.3481\n",
      "Epoch 4/150\n",
      "135/135 [==============================] - 0s 366us/step - loss: 1.9290 - accuracy: 0.3481\n",
      "Epoch 5/150\n",
      "135/135 [==============================] - 0s 285us/step - loss: 1.7483 - accuracy: 0.3481\n",
      "Epoch 6/150\n",
      "135/135 [==============================] - 0s 300us/step - loss: 1.5909 - accuracy: 0.3481\n",
      "Epoch 7/150\n",
      "135/135 [==============================] - 0s 290us/step - loss: 1.4620 - accuracy: 0.3481\n",
      "Epoch 8/150\n",
      "135/135 [==============================] - 0s 297us/step - loss: 1.3556 - accuracy: 0.3481\n",
      "Epoch 9/150\n",
      "135/135 [==============================] - 0s 285us/step - loss: 1.2743 - accuracy: 0.3481\n",
      "Epoch 10/150\n",
      "135/135 [==============================] - 0s 299us/step - loss: 1.2164 - accuracy: 0.3481\n",
      "Epoch 11/150\n",
      "135/135 [==============================] - 0s 284us/step - loss: 1.1588 - accuracy: 0.3481\n",
      "Epoch 12/150\n",
      "135/135 [==============================] - 0s 300us/step - loss: 1.1165 - accuracy: 0.3481\n",
      "Epoch 13/150\n",
      "135/135 [==============================] - 0s 288us/step - loss: 1.0857 - accuracy: 0.3481\n",
      "Epoch 14/150\n",
      "135/135 [==============================] - 0s 284us/step - loss: 1.0538 - accuracy: 0.3481\n",
      "Epoch 15/150\n",
      "135/135 [==============================] - 0s 296us/step - loss: 1.0296 - accuracy: 0.3481\n",
      "Epoch 16/150\n",
      "135/135 [==============================] - 0s 307us/step - loss: 1.0085 - accuracy: 0.3481\n",
      "Epoch 17/150\n",
      "135/135 [==============================] - 0s 292us/step - loss: 0.9885 - accuracy: 0.3481\n",
      "Epoch 18/150\n",
      "135/135 [==============================] - 0s 312us/step - loss: 0.9729 - accuracy: 0.3407\n",
      "Epoch 19/150\n",
      "135/135 [==============================] - 0s 295us/step - loss: 0.9595 - accuracy: 0.3481\n",
      "Epoch 20/150\n",
      "135/135 [==============================] - 0s 301us/step - loss: 0.9447 - accuracy: 0.3630\n",
      "Epoch 21/150\n",
      "135/135 [==============================] - 0s 301us/step - loss: 0.9329 - accuracy: 0.4000\n",
      "Epoch 22/150\n",
      "135/135 [==============================] - 0s 290us/step - loss: 0.9219 - accuracy: 0.4370\n",
      "Epoch 23/150\n",
      "135/135 [==============================] - 0s 296us/step - loss: 0.9105 - accuracy: 0.4370\n",
      "Epoch 24/150\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.9003 - accuracy: 0.4741\n",
      "Epoch 25/150\n",
      "135/135 [==============================] - 0s 302us/step - loss: 0.8912 - accuracy: 0.5704\n",
      "Epoch 26/150\n",
      "135/135 [==============================] - 0s 299us/step - loss: 0.8808 - accuracy: 0.6074\n",
      "Epoch 27/150\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.8729 - accuracy: 0.6741\n",
      "Epoch 28/150\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.8637 - accuracy: 0.6667\n",
      "Epoch 29/150\n",
      "135/135 [==============================] - 0s 294us/step - loss: 0.8535 - accuracy: 0.6519\n",
      "Epoch 30/150\n",
      "135/135 [==============================] - 0s 282us/step - loss: 0.8441 - accuracy: 0.6593\n",
      "Epoch 31/150\n",
      "135/135 [==============================] - 0s 292us/step - loss: 0.8354 - accuracy: 0.6815\n",
      "Epoch 32/150\n",
      "135/135 [==============================] - 0s 310us/step - loss: 0.8265 - accuracy: 0.6889\n",
      "Epoch 33/150\n",
      "135/135 [==============================] - 0s 300us/step - loss: 0.8178 - accuracy: 0.6889\n",
      "Epoch 34/150\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.8100 - accuracy: 0.7259\n",
      "Epoch 35/150\n",
      "135/135 [==============================] - 0s 299us/step - loss: 0.7995 - accuracy: 0.6741\n",
      "Epoch 36/150\n",
      "135/135 [==============================] - 0s 295us/step - loss: 0.7924 - accuracy: 0.6519\n",
      "Epoch 37/150\n",
      "135/135 [==============================] - 0s 365us/step - loss: 0.7834 - accuracy: 0.6593\n",
      "Epoch 38/150\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.7750 - accuracy: 0.6667\n",
      "Epoch 39/150\n",
      "135/135 [==============================] - 0s 310us/step - loss: 0.7667 - accuracy: 0.6741\n",
      "Epoch 40/150\n",
      "135/135 [==============================] - 0s 311us/step - loss: 0.7584 - accuracy: 0.6741\n",
      "Epoch 41/150\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.7510 - accuracy: 0.6741\n",
      "Epoch 42/150\n",
      "135/135 [==============================] - 0s 298us/step - loss: 0.7427 - accuracy: 0.6741\n",
      "Epoch 43/150\n",
      "135/135 [==============================] - 0s 304us/step - loss: 0.7348 - accuracy: 0.6963\n",
      "Epoch 44/150\n",
      "135/135 [==============================] - 0s 293us/step - loss: 0.7265 - accuracy: 0.7259\n",
      "Epoch 45/150\n",
      "135/135 [==============================] - 0s 313us/step - loss: 0.7187 - accuracy: 0.7556\n",
      "Epoch 46/150\n",
      "135/135 [==============================] - 0s 297us/step - loss: 0.7106 - accuracy: 0.7778\n",
      "Epoch 47/150\n",
      "135/135 [==============================] - 0s 440us/step - loss: 0.7034 - accuracy: 0.7407\n",
      "Epoch 48/150\n",
      "135/135 [==============================] - 0s 436us/step - loss: 0.6956 - accuracy: 0.7185\n",
      "Epoch 49/150\n",
      "135/135 [==============================] - 0s 396us/step - loss: 0.6888 - accuracy: 0.7852\n",
      "Epoch 50/150\n",
      "135/135 [==============================] - 0s 336us/step - loss: 0.6804 - accuracy: 0.7704\n",
      "Epoch 51/150\n",
      "135/135 [==============================] - 0s 301us/step - loss: 0.6732 - accuracy: 0.7630\n",
      "Epoch 52/150\n",
      "135/135 [==============================] - 0s 308us/step - loss: 0.6659 - accuracy: 0.8000\n",
      "Epoch 53/150\n",
      "135/135 [==============================] - 0s 343us/step - loss: 0.6606 - accuracy: 0.8370\n",
      "Epoch 54/150\n",
      "135/135 [==============================] - 0s 328us/step - loss: 0.6517 - accuracy: 0.8222\n",
      "Epoch 55/150\n",
      "135/135 [==============================] - 0s 317us/step - loss: 0.6448 - accuracy: 0.8000\n",
      "Epoch 56/150\n",
      "135/135 [==============================] - 0s 315us/step - loss: 0.6380 - accuracy: 0.8148\n",
      "Epoch 57/150\n",
      "135/135 [==============================] - 0s 329us/step - loss: 0.6312 - accuracy: 0.8370\n",
      "Epoch 58/150\n",
      "135/135 [==============================] - 0s 319us/step - loss: 0.6243 - accuracy: 0.8444\n",
      "Epoch 59/150\n",
      "135/135 [==============================] - 0s 317us/step - loss: 0.6176 - accuracy: 0.8370\n",
      "Epoch 60/150\n",
      "135/135 [==============================] - 0s 313us/step - loss: 0.6109 - accuracy: 0.8370\n",
      "Epoch 61/150\n",
      "135/135 [==============================] - 0s 322us/step - loss: 0.6054 - accuracy: 0.8222\n",
      "Epoch 62/150\n",
      "135/135 [==============================] - 0s 319us/step - loss: 0.5981 - accuracy: 0.8444\n",
      "Epoch 63/150\n",
      "135/135 [==============================] - 0s 313us/step - loss: 0.5925 - accuracy: 0.8593\n",
      "Epoch 64/150\n",
      "135/135 [==============================] - 0s 314us/step - loss: 0.5863 - accuracy: 0.8815\n",
      "Epoch 65/150\n",
      "135/135 [==============================] - 0s 334us/step - loss: 0.5801 - accuracy: 0.9037\n",
      "Epoch 66/150\n",
      "135/135 [==============================] - 0s 318us/step - loss: 0.5738 - accuracy: 0.8741\n",
      "Epoch 67/150\n",
      "135/135 [==============================] - 0s 314us/step - loss: 0.5688 - accuracy: 0.8370\n",
      "Epoch 68/150\n",
      "135/135 [==============================] - 0s 316us/step - loss: 0.5627 - accuracy: 0.8444\n",
      "Epoch 69/150\n",
      "135/135 [==============================] - 0s 345us/step - loss: 0.5576 - accuracy: 0.8963\n",
      "Epoch 70/150\n",
      "135/135 [==============================] - 0s 389us/step - loss: 0.5515 - accuracy: 0.8889\n",
      "Epoch 71/150\n",
      "135/135 [==============================] - 0s 409us/step - loss: 0.5461 - accuracy: 0.8741\n",
      "Epoch 72/150\n",
      "135/135 [==============================] - 0s 521us/step - loss: 0.5413 - accuracy: 0.8815\n",
      "Epoch 73/150\n",
      "135/135 [==============================] - 0s 547us/step - loss: 0.5358 - accuracy: 0.8741\n",
      "Epoch 74/150\n",
      "135/135 [==============================] - 0s 374us/step - loss: 0.5310 - accuracy: 0.8815\n",
      "Epoch 75/150\n",
      "135/135 [==============================] - 0s 285us/step - loss: 0.5254 - accuracy: 0.9037\n",
      "Epoch 76/150\n",
      "135/135 [==============================] - 0s 367us/step - loss: 0.5214 - accuracy: 0.9185\n",
      "Epoch 77/150\n",
      "135/135 [==============================] - 0s 371us/step - loss: 0.5168 - accuracy: 0.9407\n",
      "Epoch 78/150\n",
      "135/135 [==============================] - 0s 354us/step - loss: 0.5113 - accuracy: 0.9630\n",
      "Epoch 79/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 290us/step - loss: 0.5069 - accuracy: 0.9407\n",
      "Epoch 80/150\n",
      "135/135 [==============================] - 0s 346us/step - loss: 0.5024 - accuracy: 0.9556\n",
      "Epoch 81/150\n",
      "135/135 [==============================] - 0s 367us/step - loss: 0.4976 - accuracy: 0.9481\n",
      "Epoch 82/150\n",
      "135/135 [==============================] - 0s 343us/step - loss: 0.4939 - accuracy: 0.9111\n",
      "Epoch 83/150\n",
      "135/135 [==============================] - 0s 331us/step - loss: 0.4905 - accuracy: 0.9259\n",
      "Epoch 84/150\n",
      "135/135 [==============================] - 0s 277us/step - loss: 0.4860 - accuracy: 0.9333\n",
      "Epoch 85/150\n",
      "135/135 [==============================] - 0s 360us/step - loss: 0.4809 - accuracy: 0.9556\n",
      "Epoch 86/150\n",
      "135/135 [==============================] - 0s 389us/step - loss: 0.4771 - accuracy: 0.9556\n",
      "Epoch 87/150\n",
      "135/135 [==============================] - 0s 331us/step - loss: 0.4732 - accuracy: 0.9556\n",
      "Epoch 88/150\n",
      "135/135 [==============================] - 0s 313us/step - loss: 0.4692 - accuracy: 0.9556\n",
      "Epoch 89/150\n",
      "135/135 [==============================] - 0s 324us/step - loss: 0.4651 - accuracy: 0.9630\n",
      "Epoch 90/150\n",
      "135/135 [==============================] - 0s 295us/step - loss: 0.4611 - accuracy: 0.9630\n",
      "Epoch 91/150\n",
      "135/135 [==============================] - 0s 305us/step - loss: 0.4576 - accuracy: 0.9630\n",
      "Epoch 92/150\n",
      "135/135 [==============================] - 0s 319us/step - loss: 0.4552 - accuracy: 0.9333\n",
      "Epoch 93/150\n",
      "135/135 [==============================] - 0s 293us/step - loss: 0.4513 - accuracy: 0.9630\n",
      "Epoch 94/150\n",
      "135/135 [==============================] - 0s 323us/step - loss: 0.4471 - accuracy: 0.9630\n",
      "Epoch 95/150\n",
      "135/135 [==============================] - 0s 324us/step - loss: 0.4444 - accuracy: 0.9630\n",
      "Epoch 96/150\n",
      "135/135 [==============================] - 0s 352us/step - loss: 0.4404 - accuracy: 0.9630\n",
      "Epoch 97/150\n",
      "135/135 [==============================] - 0s 317us/step - loss: 0.4373 - accuracy: 0.9630\n",
      "Epoch 98/150\n",
      "135/135 [==============================] - 0s 357us/step - loss: 0.4348 - accuracy: 0.9630\n",
      "Epoch 99/150\n",
      "135/135 [==============================] - 0s 361us/step - loss: 0.4310 - accuracy: 0.9630\n",
      "Epoch 100/150\n",
      "135/135 [==============================] - 0s 361us/step - loss: 0.4281 - accuracy: 0.9630\n",
      "Epoch 101/150\n",
      "135/135 [==============================] - 0s 357us/step - loss: 0.4255 - accuracy: 0.9630\n",
      "Epoch 102/150\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.4220 - accuracy: 0.9630\n",
      "Epoch 103/150\n",
      "135/135 [==============================] - 0s 332us/step - loss: 0.4191 - accuracy: 0.9630\n",
      "Epoch 104/150\n",
      "135/135 [==============================] - 0s 326us/step - loss: 0.4162 - accuracy: 0.9630\n",
      "Epoch 105/150\n",
      "135/135 [==============================] - 0s 338us/step - loss: 0.4132 - accuracy: 0.9630\n",
      "Epoch 106/150\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.4125 - accuracy: 0.9630\n",
      "Epoch 107/150\n",
      "135/135 [==============================] - 0s 398us/step - loss: 0.4082 - accuracy: 0.9630\n",
      "Epoch 108/150\n",
      "135/135 [==============================] - 0s 357us/step - loss: 0.4049 - accuracy: 0.9630\n",
      "Epoch 109/150\n",
      "135/135 [==============================] - 0s 321us/step - loss: 0.4024 - accuracy: 0.9630\n",
      "Epoch 110/150\n",
      "135/135 [==============================] - 0s 322us/step - loss: 0.3997 - accuracy: 0.9630\n",
      "Epoch 111/150\n",
      "135/135 [==============================] - 0s 419us/step - loss: 0.3971 - accuracy: 0.9630\n",
      "Epoch 112/150\n",
      "135/135 [==============================] - 0s 347us/step - loss: 0.3943 - accuracy: 0.9704\n",
      "Epoch 113/150\n",
      "135/135 [==============================] - 0s 316us/step - loss: 0.3920 - accuracy: 0.9704\n",
      "Epoch 114/150\n",
      "135/135 [==============================] - 0s 361us/step - loss: 0.3901 - accuracy: 0.9630\n",
      "Epoch 115/150\n",
      "135/135 [==============================] - 0s 355us/step - loss: 0.3871 - accuracy: 0.9630\n",
      "Epoch 116/150\n",
      "135/135 [==============================] - 0s 380us/step - loss: 0.3851 - accuracy: 0.9778\n",
      "Epoch 117/150\n",
      "135/135 [==============================] - 0s 438us/step - loss: 0.3826 - accuracy: 0.9704\n",
      "Epoch 118/150\n",
      "135/135 [==============================] - 0s 335us/step - loss: 0.3804 - accuracy: 0.9704\n",
      "Epoch 119/150\n",
      "135/135 [==============================] - 0s 359us/step - loss: 0.3776 - accuracy: 0.9704\n",
      "Epoch 120/150\n",
      "135/135 [==============================] - 0s 361us/step - loss: 0.3754 - accuracy: 0.9704\n",
      "Epoch 121/150\n",
      "135/135 [==============================] - 0s 325us/step - loss: 0.3738 - accuracy: 0.9704\n",
      "Epoch 122/150\n",
      "135/135 [==============================] - 0s 291us/step - loss: 0.3709 - accuracy: 0.9704\n",
      "Epoch 123/150\n",
      "135/135 [==============================] - 0s 322us/step - loss: 0.3692 - accuracy: 0.9704\n",
      "Epoch 124/150\n",
      "135/135 [==============================] - 0s 328us/step - loss: 0.3671 - accuracy: 0.9704\n",
      "Epoch 125/150\n",
      "135/135 [==============================] - 0s 330us/step - loss: 0.3648 - accuracy: 0.9704\n",
      "Epoch 126/150\n",
      "135/135 [==============================] - 0s 286us/step - loss: 0.3627 - accuracy: 0.9704\n",
      "Epoch 127/150\n",
      "135/135 [==============================] - 0s 356us/step - loss: 0.3609 - accuracy: 0.9704\n",
      "Epoch 128/150\n",
      "135/135 [==============================] - 0s 352us/step - loss: 0.3605 - accuracy: 0.9778\n",
      "Epoch 129/150\n",
      "135/135 [==============================] - 0s 359us/step - loss: 0.3560 - accuracy: 0.9778\n",
      "Epoch 130/150\n",
      "135/135 [==============================] - 0s 364us/step - loss: 0.3564 - accuracy: 0.9630\n",
      "Epoch 131/150\n",
      "135/135 [==============================] - 0s 359us/step - loss: 0.3522 - accuracy: 0.9704\n",
      "Epoch 132/150\n",
      "135/135 [==============================] - 0s 382us/step - loss: 0.3516 - accuracy: 0.9704\n",
      "Epoch 133/150\n",
      "135/135 [==============================] - 0s 348us/step - loss: 0.3492 - accuracy: 0.9778\n",
      "Epoch 134/150\n",
      "135/135 [==============================] - 0s 334us/step - loss: 0.3474 - accuracy: 0.9852\n",
      "Epoch 135/150\n",
      "135/135 [==============================] - 0s 340us/step - loss: 0.3442 - accuracy: 0.9778\n",
      "Epoch 136/150\n",
      "135/135 [==============================] - 0s 374us/step - loss: 0.3434 - accuracy: 0.9704\n",
      "Epoch 137/150\n",
      "135/135 [==============================] - 0s 371us/step - loss: 0.3422 - accuracy: 0.9704\n",
      "Epoch 138/150\n",
      "135/135 [==============================] - 0s 410us/step - loss: 0.3395 - accuracy: 0.9704\n",
      "Epoch 139/150\n",
      "135/135 [==============================] - 0s 363us/step - loss: 0.3403 - accuracy: 0.9704\n",
      "Epoch 140/150\n",
      "135/135 [==============================] - 0s 333us/step - loss: 0.3362 - accuracy: 0.9704\n",
      "Epoch 141/150\n",
      "135/135 [==============================] - 0s 293us/step - loss: 0.3338 - accuracy: 0.9704\n",
      "Epoch 142/150\n",
      "135/135 [==============================] - 0s 310us/step - loss: 0.3316 - accuracy: 0.9778\n",
      "Epoch 143/150\n",
      "135/135 [==============================] - 0s 346us/step - loss: 0.3297 - accuracy: 0.9704\n",
      "Epoch 144/150\n",
      "135/135 [==============================] - 0s 329us/step - loss: 0.3288 - accuracy: 0.9852\n",
      "Epoch 145/150\n",
      "135/135 [==============================] - 0s 345us/step - loss: 0.3273 - accuracy: 0.9704\n",
      "Epoch 146/150\n",
      "135/135 [==============================] - 0s 337us/step - loss: 0.3250 - accuracy: 0.9778\n",
      "Epoch 147/150\n",
      "135/135 [==============================] - 0s 363us/step - loss: 0.3226 - accuracy: 0.9852\n",
      "Epoch 148/150\n",
      "135/135 [==============================] - 0s 378us/step - loss: 0.3210 - accuracy: 0.9852\n",
      "Epoch 149/150\n",
      "135/135 [==============================] - 0s 366us/step - loss: 0.3206 - accuracy: 0.9704\n",
      "Epoch 150/150\n",
      "135/135 [==============================] - 0s 371us/step - loss: 0.3208 - accuracy: 0.9778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a408290d0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=10, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_p6yilvas2kZ"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_test_class = np.argmax(y_test,axis=1)\n",
    "y_pred_class = np.argmax(y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "WrgLET2Ns22J",
    "outputId": "a53a01f5-1119-4cc9-cad7-469eafb7a247"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      0.67      0.80         3\n",
      "           2       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.95      0.89      0.91        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n",
      "[[6 0 0]\n",
      " [0 2 1]\n",
      " [0 0 6]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test_class,y_pred_class))\n",
    "print(confusion_matrix(y_test_class,y_pred_class))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Multiple Classificaiton using IRIS Dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
